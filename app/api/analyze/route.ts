import { RemoveMessage, SystemMessage } from "@langchain/core/messages";
import {
  Annotation,
  MemorySaver,
  MessagesAnnotation,
  StateGraph,
} from "@langchain/langgraph";

import { jsonParser, OpenAi4_1Mini, strParser } from "@/lib/models";
import {
  humanProfileDescriptions,
  validateProfile,
  HumanProfile,
} from "./personal";
import { PromptTemplate } from "@langchain/core/prompts";
import { getBaseUrl } from "@/lib/contents";

// /** ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æŒ¿å…¥ã™ã‚‹å‡¦ç† */
async function insertMessages(state: typeof GraphAnnotation.State) {
  console.log("ğŸ“© insart messages");

  console.log(state.messages);
  const messages = state.messages;

  return { messages: messages };
}

/** åˆ†æã‚’è¡Œã†ã‹ã®åˆ¤æ–­å‡¦ç† */
async function shouldAnalyze(state: typeof GraphAnnotation.State) {
  console.log("â“ should analyze");
  const messages = state.messages;

  if (messages.length > 3) return "analyzeNode";
  return "__end__";
}

/** ä¼šè©±ã®åˆ†æå‡¦ç† */
async function analyzeConversation(state: typeof GraphAnnotation.State) {
  console.log("ğŸ“ƒ analyze conversation");
  let analyzeContext = state.analyze;

  let analyzeMessage;
  if (analyzeContext) {
    analyzeMessage = `ã“ã‚Œã¾ã§ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ†æ: ${analyzeContext}
    
    ä¸Šè¨˜ã®æ–°ã—ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è€ƒæ…®ã—ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ†æã‚’æ‹¡å¼µã—ã¦ãã ã•ã„ã€‚
    ä»¥ä¸‹ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¾“ã£ã¦ã€ã“ã‚Œã¾ã§ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ†æã«è¿½è¨˜ã€ã‚‚ã—ãã¯ç™ºå±•ã™ã‚‹å½¢ã§æ›´æ–°ã—ã¦ã€å‡ºåŠ›ã‚’JSONå½¢å¼ã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
    
    å‡ºåŠ›å½¢å¼ï¼š
      ${humanProfileDescriptions} `;
  } else {
    analyzeMessage = `ä¸Šè¨˜ã®å…¥åŠ›ã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æƒ…å ±ã‚„è¶£å‘³è¶£å‘ã‚„ç‰¹å¾´ãªã©ã‚’åˆ†æã—ã€ãƒ‘ãƒ¼ã‚½ãƒŠãƒ«æƒ…å ±ã¨ã—ã¦è¨˜éŒ²ã—ã¦ãã ã•ã„ã€‚ 
  ä»¥ä¸‹ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¾“ã£ã¦ã€å‡ºåŠ›ã‚’JSONå½¢å¼ã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
  æƒ…å ±ãŒèª­ã¿å–ã‚Œãªã‹ã£ãŸå ´åˆã¯ç©ºæ¬„ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

  å‡ºåŠ›å½¢å¼ï¼š
    ${humanProfileDescriptions}`;
  }

  // è¦ç´„å‡¦ç†
  const messages = [...state.messages, new SystemMessage(analyzeMessage)];
  const response = await OpenAi4_1Mini.pipe(jsonParser).invoke(messages);

  console.log(response);
  const validProfile = validateProfile(response);
  if (validProfile) analyzeContext = validProfile;

  // è¦ç´„ã—ãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é™¤å»
  const deleteMessages = messages
    .slice(0, -1)
    .map((m) => new RemoveMessage({ id: m.id! }));

  return { analyze: analyzeContext, messages: deleteMessages };
}

async function generateUserText(state: typeof GraphAnnotation.State) {
  const analyzeContext = state.analyze;

  let context = "";
  if (analyzeContext) {
    const template = `ä»¥ä¸‹ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ†æã‚’ã»ã‹ã® LLM ãŒæƒ…å ±ã‚’æ‰±ã„ã‚„ã™ã„ã‚ˆã†ã«å…·ä½“çš„ãªæ–‡ç« ã¨ã—ã¦è¦ç´„ã—ã¦ãã ã•ã„ã€‚\n\n{analyze_context}`;

    const prompt = PromptTemplate.fromTemplate(template);
    context = await prompt
      .pipe(OpenAi4_1Mini)
      .pipe(strParser)
      .invoke({ analyze_context: analyzeContext });
  }
  console.log(context);
  const messages = [...state.messages, new SystemMessage(context)];
  return { context: context, messages: messages };
}

// ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®è¿½åŠ 
const GraphAnnotation = Annotation.Root({
  analyze: Annotation<HumanProfile>(),
  context: Annotation<string>(),
  ...MessagesAnnotation.spec,
});

// ã‚°ãƒ©ãƒ•
const workflow = new StateGraph(GraphAnnotation)
  // ãƒãƒ¼ãƒ‰è¿½åŠ 
  .addNode("insertNode", insertMessages)
  .addNode("analyzeNode", analyzeConversation)
  .addNode("textNode", generateUserText)

  // ã‚¨ãƒƒã‚¸è¿½åŠ 
  .addEdge("__start__", "insertNode")
  .addConditionalEdges("insertNode", shouldAnalyze)
  .addEdge("analyzeNode", "textNode")
  .addEdge("textNode", "__end__");

// è¨˜æ†¶ã®è¿½åŠ 
const memory = new MemorySaver();
const app = workflow.compile({ checkpointer: memory });

/**
 * ä¼šè©±å±¥æ­´è¦ç´„API
 * @param req
 * @returns
 */
export async function POST(req: Request) {
  try {
    const body = await req.json();
    const userMessages = body.userMessages;
    const threadId = body.sessionId ?? "analyze-abc123";
    const { baseUrl } = getBaseUrl(req);

    console.log("ğŸ“‚ Analize API | ID: " + threadId);
    const currentUserMessages = userMessages[userMessages.length - 1];

    // å±¥æ­´ç”¨ã‚­ãƒ¼
    const config = { configurable: { thread_id: threadId } };
    const results = await app.invoke({ messages: currentUserMessages }, config);

    // DB ã¸ã®è¿½åŠ 
    const analyzeData = results.analyze;
    if (analyzeData) {
      const res = await fetch(baseUrl + "/api/prisma/create-personal", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ analyzeData, threadId }),
      });
      const data = await res.json();
      console.log(data);
    }

    return new Response(JSON.stringify(results), {
      status: 200,
      headers: { "Content-Type": "application/json" },
    });
  } catch (error) {
    if (error instanceof Error) {
      console.log("ğŸ“‚ Analize API error" + error);
      return new Response(JSON.stringify({ error: error.message }), {
        status: 500,
        headers: { "Content-Type": "application/json" },
      });
    }

    return new Response(JSON.stringify({ error: "Unknown error occurred" }), {
      status: 500,
      headers: { "Content-Type": "application/json" },
    });
  }
}
