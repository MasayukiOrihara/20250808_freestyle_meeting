import { RemoveMessage, SystemMessage } from "@langchain/core/messages";
import {
  Annotation,
  MemorySaver,
  MessagesAnnotation,
  StateGraph,
} from "@langchain/langgraph";

import { jsonParser, OpenAi4_1Mini } from "@/lib/models";
import {
  humanProfileDescriptions,
  validateProfile,
  HumanProfile,
} from "./personal";

// /** ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æŒ¿å…¥ã™ã‚‹å‡¦ç† */
async function insertMessages(state: typeof GraphAnnotation.State) {
  console.log("ğŸ“© insart messages");

  console.log(state.messages);
  const messages = state.messages;

  return { messages: messages };
}

/** åˆ†æã‚’è¡Œã†ã‹ã®åˆ¤æ–­å‡¦ç† */
async function shouldAnalyze(state: typeof GraphAnnotation.State) {
  console.log("â“ should analyze");
  const messages = state.messages;

  if (messages.length > 2) return "analyzeNode";
  return "__end__";
}

/** ä¼šè©±ã®åˆ†æå‡¦ç† */
async function analyzeConversation(state: typeof GraphAnnotation.State) {
  console.log("ğŸ“ƒ analyze conversation");
  let analyzeContext = state.analyze;

  console.log(analyzeContext);

  let analyzeMessage;
  if (analyzeContext) {
    analyzeMessage = `ã“ã‚Œã¾ã§ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ†æ: ${analyzeContext}
    
    ä¸Šè¨˜ã®æ–°ã—ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è€ƒæ…®ã—ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ†æã‚’æ‹¡å¼µã—ã¦ãã ã•ã„ã€‚
    ä»¥ä¸‹ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¾“ã£ã¦ã€ã“ã‚Œã¾ã§ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ†æã«è¿½è¨˜ã€ã‚‚ã—ãã¯ç™ºå±•ã™ã‚‹å½¢ã§æ›´æ–°ã—ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
    
    å‡ºåŠ›å½¢å¼ï¼š
      ${humanProfileDescriptions} `;
  } else {
    analyzeMessage = `ä¸Šè¨˜ã®å…¥åŠ›ã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æƒ…å ±ã‚„è¶£å‘³è¶£å‘ã‚„ç‰¹å¾´ãªã©ã‚’åˆ†æã—ã€ãƒ‘ãƒ¼ã‚½ãƒŠãƒ«æƒ…å ±ã¨ã—ã¦è¨˜éŒ²ã—ã¦ãã ã•ã„ã€‚ 
  ä»¥ä¸‹ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¾“ã£ã¦ã€å‡ºåŠ›ã‚’JSONå½¢å¼ã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
  æƒ…å ±ãŒèª­ã¿å–ã‚Œãªã‹ã£ãŸå ´åˆã¯ç©ºæ¬„ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

  å‡ºåŠ›å½¢å¼ï¼š
    ${humanProfileDescriptions}`;
  }

  // è¦ç´„å‡¦ç†
  const messages = [...state.messages, new SystemMessage(analyzeMessage)];
  const response = await OpenAi4_1Mini.pipe(jsonParser).invoke(messages);

  const validProfile = validateProfile(response);
  console.log(validProfile);
  if (validProfile) analyzeContext = validProfile;

  // è¦ç´„ã—ãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é™¤å»
  const deleteMessages = messages
    .slice(0, -1)
    .map((m) => new RemoveMessage({ id: m.id! }));

  return { analyze: analyzeContext, messages: deleteMessages };
}

// ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®è¿½åŠ 
const GraphAnnotation = Annotation.Root({
  analyze: Annotation<HumanProfile>(),
  ...MessagesAnnotation.spec,
});

// ã‚°ãƒ©ãƒ•
const workflow = new StateGraph(GraphAnnotation)
  // ãƒãƒ¼ãƒ‰è¿½åŠ 
  .addNode("insertNode", insertMessages)
  .addNode("analyzeNode", analyzeConversation)

  // ã‚¨ãƒƒã‚¸è¿½åŠ 
  .addEdge("__start__", "insertNode")
  .addConditionalEdges("insertNode", shouldAnalyze)
  .addEdge("analyzeNode", "__end__");

// è¨˜æ†¶ã®è¿½åŠ 
const memory = new MemorySaver();
const app = workflow.compile({ checkpointer: memory });

/**
 * ä¼šè©±å±¥æ­´è¦ç´„API
 * @param req
 * @returns
 */
export async function POST(req: Request) {
  try {
    const body = await req.json();
    const userMessages = body.userMessages;

    console.log("ğŸ“‚ Analize API");
    const currentUserMessages = userMessages[userMessages.length - 1];

    // å±¥æ­´ç”¨ã‚­ãƒ¼
    const config = { configurable: { thread_id: "abc123" } };
    const results = await app.invoke({ messages: currentUserMessages }, config);

    return new Response(JSON.stringify(results.analyze), {
      status: 200,
      headers: { "Content-Type": "application/json" },
    });
  } catch (error) {
    if (error instanceof Error) {
      console.log("ğŸ“‚ Analize API error" + error);
      return new Response(JSON.stringify({ error: error.message }), {
        status: 500,
        headers: { "Content-Type": "application/json" },
      });
    }

    return new Response(JSON.stringify({ error: "Unknown error occurred" }), {
      status: 500,
      headers: { "Content-Type": "application/json" },
    });
  }
}
