import {
  BaseMessage,
  RemoveMessage,
  SystemMessage,
} from "@langchain/core/messages";
import {
  Annotation,
  MemorySaver,
  MessagesAnnotation,
  StateGraph,
} from "@langchain/langgraph";

import { OpenAi4_1Mini } from "@/lib/models";
import {
  local,
  MEMORY_SUMMARY_PROMPT,
  MEMORY_UPDATE_PROMPT,
} from "@/lib/contents";
import {
  getConversasionSearch,
  getMessagSearch,
  postConversasionGenerate,
  postConversasionMessages,
} from "@/lib/api";
import { formatContent, formatConversation } from "./utils";

// å®šæ•°
const SUMMARY_MAX_COUNT = 8;

/** ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å–å¾—ã™ã‚‹å‡¦ç† */
async function insartMessage(state: typeof GraphAnnotation.State) {
  const formatted: string[] = [];
  const messages = state.messages;

  console.log("===insartMessage===");
  console.log(messages);
  console.log("======");

  // conversation ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’å‚ç…§
  let conversationId: string = await getConversasionSearch(state.sessionId);
  if (!conversationId) {
    // ã‚‚ã—å–å¾—ã§ããªã‹ã£ãŸå ´åˆã€æ–°ãŸã«conversationã‚’ä½œæˆã™ã‚‹
    conversationId = await postConversasionGenerate(state.sessionId);
    return { formatted: formatted };
  }

  // DB ã‹ã‚‰ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’xä»¶å–å¾—ã™ã‚‹
  const latestTwoMessage: string = await getMessagSearch(conversationId, 3);
  console.log("ğŸ¶ latestTwoMessage: ");
  console.log(latestTwoMessage);
  return { formatted: [...formatted, ...latestTwoMessage] };
}

/** ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ DB ã«ç™»éŒ²ã™ã‚‹å‡¦ç† */
async function storeMessage(state: typeof GraphAnnotation.State) {
  const messages = state.messages;
  const formatted: string[] = state.formatted;
  console.log("===storeMessage===");
  console.log(messages);
  console.log("======");

  // conversation ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’å‚ç…§
  let conversationId: string = await getConversasionSearch(state.sessionId);
  if (!conversationId) {
    // ã‚‚ã—å–å¾—ã§ããªã‹ã£ãŸå ´åˆã€æ–°ãŸã«conversationã‚’ä½œæˆã™ã‚‹
    conversationId = await postConversasionGenerate(state.sessionId);
  }

  // messages ãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜
  const { roles, contents } = formatContent(messages, state.sessionId);
  const length = Math.min(roles.length, contents.length);
  for (let i = 0; i < length; i++) {
    await postConversasionMessages(conversationId, roles[i], contents[i]);
  }

  // åŠ å·¥å¾Œã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ ã™ã‚‹
  const formattedMessages: string[] = formatConversation(roles, contents);

  console.log("======");
  console.log(formattedMessages);
  console.log("======");

  console.log("ğŸ¶: ");
  console.log(formatted);
  // ä½¿ã£ãŸ messages ã¯åˆæœŸåŒ–
  const deleteMessages = messages.map((m) => new RemoveMessage({ id: m.id! }));
  return {
    messages: deleteMessages,
    formatted: [...formatted, ...formattedMessages],
  };
}

/** è¦ç´„ã—ãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ ã™ã‚‹å‡¦ç† */
async function prepareMessages(state: typeof GraphAnnotation.State) {
  const summary = state.summary;

  // è¦ç´„ã‚’ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ã—ã¦è¿½åŠ 
  const systemMessage = `Previous conversation summary: ${summary}`;
  const messages = [new SystemMessage(systemMessage)];

  // ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
  const { roles, contents } = formatContent(messages, state.sessionId);
  const conversation: string[] = formatConversation(roles, contents);

  console.log("ğŸ¶: " + state.formatted);
  return { formatted: [...conversation] };
}

/** ä¼šè©±ã‚’è¡Œã†ã‹è¦ç´„ã™ã‚‹ã‹ã®åˆ¤æ–­å‡¦ç† */
async function shouldContenue(state: typeof GraphAnnotation.State) {
  const formatted = state.formatted;

  console.log("ğŸ¶: " + formatted);
  if (formatted.length > SUMMARY_MAX_COUNT) return "summarize";
  return "__end__";
}

/** ä¼šè©±ã®è¦ç´„å‡¦ç† */
async function summarizeConversation(state: typeof GraphAnnotation.State) {
  const summary = state.summary;

  let summaryMessage;
  if (summary) {
    summaryMessage = MEMORY_UPDATE_PROMPT.replace("{summary}", summary);
  } else {
    summaryMessage = MEMORY_SUMMARY_PROMPT;
  }

  // è¦ç´„å‡¦ç†
  const messages = [new SystemMessage(summaryMessage)];
  const { roles, contents } = formatContent(messages, state.sessionId);
  const conversation: string[] = formatConversation(roles, contents);

  const formatted = [...state.formatted, ...conversation];
  const response = await OpenAi4_1Mini.invoke(formatted);

  return { summary: response.content };
}

// ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®è¿½åŠ 
const GraphAnnotation = Annotation.Root({
  formatted: Annotation<string[]>(),
  summary: Annotation<string>(),
  sessionId: Annotation<string>(),

  ...MessagesAnnotation.spec,
});

// ã‚°ãƒ©ãƒ•
const workflow = new StateGraph(GraphAnnotation)
  // ãƒãƒ¼ãƒ‰è¿½åŠ 
  .addNode("insart", insartMessage)
  .addNode("save", storeMessage)
  .addNode("prepare", prepareMessages)
  .addNode("summarize", summarizeConversation)

  // ã‚¨ãƒƒã‚¸è¿½åŠ 
  .addEdge("__start__", "insart")
  .addEdge("insart", "save")
  .addConditionalEdges("save", shouldContenue)
  .addEdge("summarize", "prepare")
  .addEdge("prepare", "__end__");

// è¨˜æ†¶ã®è¿½åŠ 
const memory = new MemorySaver();
const app = workflow.compile({ checkpointer: memory });
const cacheIdList: string[] = [];

/**
 * ä¼šè©±å±¥æ­´è¦ç´„API
 * @param req
 * @returns
 */
export async function POST(req: Request) {
  try {
    const body = await req.json();
    const messages = body.messages ?? [];
    const threadId = body.threadId ?? "memory-abc123";

    // 2è¡Œå–å¾—
    const len = messages.length;
    const previousMessage: BaseMessage[] = messages.slice(
      Math.max(0, len - 2),
      len
    );

    // å±¥æ­´ç”¨ã‚­ãƒ¼
    const config = { configurable: { thread_id: threadId } };
    const results = await app.invoke(
      { messages: previousMessage, sessionId: threadId },
      config
    );

    // ä¼šè©±å±¥æ­´ã‚’è¨˜éŒ²ã—ãŸ id ã‚’ãŸã‚è¾¼ã‚€
    const haveNotId = cacheIdList.every((id) => id !== threadId);
    if (haveNotId) {
      cacheIdList.push(threadId);
    }

    console.log(results.formatted);

    return new Response(JSON.stringify(results.formatted), {
      status: 200,
      headers: { "Content-Type": "application/json" },
    });
  } catch (error) {
    if (error instanceof Error) {
      return new Response(JSON.stringify({ error: error.message }), {
        status: 500,
        headers: { "Content-Type": "application/json" },
      });
    }

    return new Response(JSON.stringify({ error: "Unknown error occurred" }), {
      status: 500,
      headers: { "Content-Type": "application/json" },
    });
  }
}

/**
 * ã™ã¹ã¦ã®ä¼šè©±å±¥æ­´è¦ç´„API
 * @returns
 */
export async function GET() {
  try {
    if (cacheIdList && cacheIdList.length > 0) {
      for (const cache of cacheIdList) {
        const config = { configurable: { thread_id: cache } };
        const savedState = await memory.get(config);

        console.log(savedState);
      }
    }
    return new Response(JSON.stringify("conversation"), {
      status: 200,
      headers: { "Content-Type": "application/json" },
    });
  } catch (error) {
    if (error instanceof Error) {
      return new Response(JSON.stringify({ error: error.message }), {
        status: 500,
        headers: { "Content-Type": "application/json" },
      });
    }

    return new Response(JSON.stringify({ error: "Unknown error occurred" }), {
      status: 500,
      headers: { "Content-Type": "application/json" },
    });
  }
}
